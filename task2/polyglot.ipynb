{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ed87cc6-2f49-491d-8e33-0e2bfc853d2a",
   "metadata": {},
   "source": [
    "### Крапчатов Михаил Б05-131\n",
    "\n",
    "# Задание 2: распознавание рукописных китайских иероглифов\n",
    "\n",
    "## Описание\n",
    "\n",
    "Предлагается реализовать и протестировать обучаемое распознавание символов на примере датасета `CASIA Offline Chinese Handwriting`\n",
    "\n",
    "Данные можно взять [тут](https://disk.yandex.ru/d/xY5CBA77vwkVew), от оригинальных отличаются переводом формата из бинарного в lmdb. Лицензию на использование данных можно посмотреть на [официальном сайте](http://www.nlpr.ia.ac.cn/databases/handwriting/Application_form.html)\n",
    "\n",
    "## Задача\n",
    "\n",
    "Реализовать алгоритм распознавания китайских рукописных символов и протестировать его на данной тестовой выборке. Можно использовать как идеи с лекции, так и любые другие способы, которые покажутся вам уместными.\n",
    "\n",
    "### Условия\n",
    "\n",
    "- Разрешается использовать готовые реализации стандартных и нестандарных слоев или лоссов\n",
    "- Разрешается использование дополнительных синтетических данных при обучении (псевдорукописные шрифты и прочее), однако способ их получения должен быть описан в решении\n",
    "- Разрешается модифицировать ОБУЧАЮЩУЮ выборку любым способом, аугментации приветствуются. Тестовую выборку использовать кроме как для тестирования запрещено\n",
    "- Запрещено использовать любые другие датасеты, а также альтернативные сплиты casia hwdb (в них часть тестовой выборки может оказаться в вашей обучающей)\n",
    "\n",
    "## Метрика\n",
    "\n",
    "Accuracy по результатам на тестовой выборке. Код для сохранения результата и локального вычисления метрики можно найти в `Baseline.ipynb`\n",
    "\n",
    "Для работы автоматического подсчета метрики в github actions нужно закоммитить файл pred.txt в свой репозиторий. Если github actions не включены - включите их в `https://github.com/{USERNAME}/course_ocr/actions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec8f45e-86cf-4519-8472-28cc87829556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "931e1c41-4faa-4161-b293-6cf6711674b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import cv2\n",
    "\n",
    "import lightning\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from pynvml import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f03348-65eb-4201-b5dc-cef5c2e4ed1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.device('cuda:0') if torch.cuda.is_available() else\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e45871c-488a-488a-b797-a6f8be5f0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5d1df8e-65af-45c4-a6f0-2a5589fe090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e9b9ad6-ef17-4001-9204-96e53e6c2d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device[cuda] with index[0]\n",
      "total    : 11811160064\n",
      "free     : 3172597760\n",
      "used     : 8638562304\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else  torch.device(\"cpu\")\n",
    "print(f'device[{device.type}] with index[{device.index}]')\n",
    "\n",
    "t = torch.cuda.get_device_properties(device.index).total_memory\n",
    "r = torch.cuda.memory_reserved(device.index)\n",
    "a = torch.cuda.memory_allocated(device.index)\n",
    "f = r-a\n",
    "nvmlInit()\n",
    "h = nvmlDeviceGetHandleByIndex(device.index)\n",
    "info = nvmlDeviceGetMemoryInfo(h)\n",
    "print(f'total    : {info.total}')\n",
    "print(f'free     : {info.free}')\n",
    "print(f'used     : {info.used}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7497728b-36c1-42f9-b198-bfbaaa3a5b81",
   "metadata": {},
   "source": [
    "**Датасет**\\\n",
    "Скачал, распаковал датасет в папку, лежащую в папке с `.git` репозиторием. Далее команды из `Baseline.ipynb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c36ce85-d3a1-4bb8-8be0-1ceaf8fd8931",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('../../lmdb').resolve()\n",
    "train_path = os.path.join(root, 'train.lmdb')\n",
    "test_path = os.path.join(root, 'test.lmdb')\n",
    "gt_path = './gt.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eefe070-093d-4073-9b62-41a1b7db39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reader import Vocabulary, HWDBDatasetHelper, LMDBReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbac17ed-beb0-4e69-ac47-b70fb53d48cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reader = LMDBReader(train_path)\n",
    "train_reader.open()\n",
    "train_helper = HWDBDatasetHelper(train_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ed2ca55-8bed-479c-9120-1705f2634c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2578433, 644609)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_helper, val_helper = train_helper.train_val_split()\n",
    "train_helper.size(), val_helper.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d49fedb-9652-4a4d-9c56-f548038aeac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0665e92bc0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "img, label = train_helper.get_item(22)\n",
    "# print(img)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b63ebe3b-0224-4337-af3c-f61480ddb97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff8e7314-8770-4448-b6aa-4684fa3553cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ff14c1-481a-4b7b-950d-18273ca66d50",
   "metadata": {},
   "source": [
    "**Небольшая обработка**\\\n",
    "Я оставлю приведение к одному `shape` только к болеевысокому разрешению (64,64) и\n",
    "добавлю упрощение картинки: всего будет 3 цвета, где я буду красить лишь самые яркие\n",
    "пиксели на картинке, мне кажется, это сделает работу модели более точной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0af2927a-89e6-47f8-b4e6-266dbdf0b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HWDBDataset(Dataset):\n",
    "    def __init__(self, helper: HWDBDatasetHelper, img_sz=64):\n",
    "        self.helper = helper\n",
    "        # I think (32,32) is too inaccurate\n",
    "        self.img_sz = img_sz\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.helper.size()\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.helper.get_item(idx)\n",
    "        img = (cv2.resize(img, (self.img_sz, self.img_sz)) - 127.5) / 255.\n",
    "\n",
    "        # Simplification of colors in image\n",
    "        # Simplify counters\n",
    "        for y in range(len(img)):\n",
    "            for x in range(len(img[0])):\n",
    "                img[y][x] = np.float32(1 if img[y][x] > 0.12 else .1 if img[y][x] > -.05 else -1)\n",
    "        return torch.tensor(img).to(device), torch.tensor(label).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cdd50db8-c7b3-405a-9f5c-c18204ab0a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f001d449420>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAI1ElEQVR4nO3dS27bWhZA0atCutQAnGFaw3CGmQxAGoCqE+wCKmIsxtR/raYtOIxie+M+nne4GWMcBwCMMf5z6wsA4H6IAgARBQAiCgBEFACIKAAQUQAg38594dvb2zgcDpe8FgAuaJqm8evXr7++5qwovL29jZ8/f65yUQDczvfv3/8ahrP+85ETAsBz+Oz3uXsKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIN9ufQHA/frx48fJj+92u5Mf//j4OPnx9/f31a6Jy3JSACCiAEBEAYCIAgARBQBi+ugOnJrwMK3BPZibMuJ5OSkAEFEAIKIAQEQBgIgCANmMMY6fvWiaprHf769wOa9pbr/MKaaSuKbNZrPK1zkeP/01w5Vst9txOBxmP++kAEBEAYCIAgARBQAiCgDE7iO4oSWTZ3PWmkhb41p4fE4KAEQUAIgoABBRACDWXMAVzN3EXfIQm1usirDm4vlYcwHA2UQBgIgCABEFACIKAMSaizu11soBD+W5rjWmjOCWnBQAiCgAEFEAIKIAQEQBgJg+ulNzU0Nr7aIxlfR1pyaN1poyupddQR8fHyc/bprqeTkpABBRACCiAEBEAYCIAgAxffRglk6DLJkSMZF0OXP/bt7zr5vbN+W9/TdOCgBEFACIKAAQUQAgbjQ/mLmbZ9YOXI4H53zdGutZ5m7Wsy4nBQAiCgBEFACIKAAQUQAgpo+exNLJDCsA/rR0yujUe37JiaS561vq3qemrAS5LScFACIKAEQUAIgoABBRACCbMcbxsxdN0zT2+/0VLod/tcZkyqtPd6w13XPK0vd2jV1B9+TURNGrf7/dyna7HYfDYfbzTgoARBQAiCgAEFEAIKIAQOw+ghW9+pTRHJNGj8NJAYCIAgARBQAiCgBEFACI3Ufw29wk0BpPAnvU3VRrTUcdj5/+muFK7D4C4GyiAEBEAYCIAgBxo5mXs/Sm7yuvaHCj+fm40QzA2UQBgIgCABEFACIKAMT0ETBr6fSRKaP7Z/oIgLOJAgARBQAiCgBEFADIt1tfAHC/1njAEI/FSQGAiAIAEQUAIgoARBQAiOkjYIyx/Il0PCcnBQAiCgBEFACIKAAQUQAgpo+AMcYYu93uj4/N7T7ieTkpABBRACCiAEBEAYC40QyMMcY4Ho+3vgTugJMCABEFACIKAEQUAIgoABDTR/Cklj405/39/UJXchubzeaPj82t7Xi2v/tXOCkAEFEAIKIAQEQBgIgCANmMMT5deDJN09jv91e4HGAtc9NHl5y0mfszTz3A5xE84z6o7XY7DofD7OedFACIKAAQUQAgogBARAGAmD6CF/NsE0Jz5vYcnfJKu49MHwFwNlEAIKIAQEQBgHjIDtyhUzeD526GPuqN4yU3gv/FK908XpOTAgARBQAiCgBEFACIKAAQay7gQcxNGV2SCZ7nY80FAGcTBQAiCgBEFACIKAAQ00cXMDclYpIDuDXTRwCcTRQAiCgAEFEAIKIAQDx57QtusYsG4JKcFACIKAAQUQAgogBARAGAmD46k0kj4BU4KQAQUQAgogBARAGAuNH8BR6aAzwbJwUAIgoARBQAiCgAEFEAIKaPvmBu9YWpJOBROSkAEFEAIKIAQEQBgIgCADF9dKbdbvfHxz4+Pm5wJQCX46QAQEQBgIgCABEFACIKAMT00f+Z22cEr2itnwf7wB6HkwIAEQUAIgoARBQAiBvN8NvSm6qnVp/MmVuJcu83YJf8HZd+nUd9T56dkwIAEQUAIgoARBQAiCgAENNH8NtakzbPZG5CaI33aunXMJV0HU4KAEQUAIgoABBRACCiAEA2Y4zjZy+apmns9/srXM79WrIXx5TEY9psNhf72q+y52fJz8mlp71OvefP9n7/i+12Ow6Hw+znnRQAiCgAEFEAIKIAQEQBgNh9dKYlT466J6amuKYl30NLv98uOR3G/zgpABBRACCiAEBEAYCIAgCx++hMSyYfbrHnZsmU0RgmjU655HTL8fjpjxm/zX0vL92V5D0/ze4jAM4mCgBEFACIKAAQay4ezFo34U5x8/ly5v7dvOdf9wjrZh6JkwIAEQUAIgoARBQAiCgAENNHd2rpyoVbrNZ4NnPvocmu++B7/DqcFACIKAAQUQAgogBARAGAmD66ojUe4mIC43KWvoenppLs4TmffVD3yUkBgIgCABEFACIKAEQUAIjpoztlyohn53v5PjkpABBRACCiAEBEAYBsxhjHz140TdPY7/dXuJzH4n/Tf21L1pYcj5/+mMFVbLfbcTgcZj/vpABARAGAiAIAEQUAIgoAxJqLLzBl9No8UIdn5KQAQEQBgIgCABEFACIKAMTuI4AXYvcRAGcTBQAiCgBEFACIKAAQu4/gSXkyIP/CSQGAiAIAEQUAIgoARBQAiOkjeHBzU0b39Gfudrsv/5lzT7ozTbUuJwUAIgoARBQAiCgAEDea4YZucZN4s9lc/c/kcTgpABBRACCiAEBEAYCIAgDZjDGOn71omqax3++vcDkAXNJ2ux2Hw2H2804KAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgDkrChM03Tp6wDgCj77fb4ZYxzP+UJvb2/jcDiscU0A3MA0TePXr19/fc3ZUQDg+bmnAEBEAYCIAgARBQAiCgBEFACIKACQ/wLPkKJ4KUSKVAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from torch.utils.data.dataloader import default_collate\n",
    "train_dataset = HWDBDataset(train_helper)\n",
    "val_dataset   = HWDBDataset(val_helper)\n",
    "\n",
    "batch_size = 1024\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True,  num_workers=0, drop_last=True)\n",
    "val_dataloader   = DataLoader(val_dataset,   batch_size, shuffle=False, num_workers=0)\n",
    "img = train_dataset[22][0]\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(img.cpu(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd72760-2309-4862-ae9c-f5ad997fc2cb",
   "metadata": {},
   "source": [
    "## Работа с моделью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1de36061-626a-49f2-8eda-679b8400a6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from pytorch_metric_learning.losses import ArcFaceLoss\n",
    "import torchvision\n",
    "print(next(iter(train_dataloader))[0].device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59d90fb5-bf52-4153-a66e-57faf6e086da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e677e965-254b-4ecf-a043-68bb3c0dac6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "880"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fccdca1-14e7-4abc-a336-49689c3fd8d8",
   "metadata": {},
   "source": [
    "Сперва попробовал `SGD`, но он сходился крайне медленно, поэтому решил переделать на Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1df57c0c-b325-4217-b4ff-ca5e423a7be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = ArcFaceLoss(num_classes=train_helper.vocabulary.num_classes(), embedding_size=1000).to(device)\n",
    "net = torchvision.models.resnet50(train_helper.vocabulary.num_classes(),pretrained=True).to(device)\n",
    "optim = torch.optim.Adam(params=net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37fe8732-60ff-400b-b0d4-5054ac786be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf047fd9-9d6d-41dc-96ae-7de5009df58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a52e765c374504b34f519890b8da71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtloader len:2518\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b727e1245b4b70b5ebd8ac41162ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss [1, 10](epoch, minibatch):  4.52669734954834\n",
      "Loss [1, 20](epoch, minibatch):  4.053141784667969\n",
      "Loss [1, 30](epoch, minibatch):  4.0302237701416015\n",
      "Loss [1, 40](epoch, minibatch):  4.0150054168701175\n",
      "Loss [1, 50](epoch, minibatch):  4.000202407836914\n",
      "Loss [1, 60](epoch, minibatch):  3.9889429092407225\n",
      "Loss [1, 70](epoch, minibatch):  3.970701789855957\n",
      "Loss [1, 80](epoch, minibatch):  3.951416015625\n",
      "Loss [1, 90](epoch, minibatch):  3.9362102508544923\n",
      "Loss [1, 100](epoch, minibatch):  3.9166698455810547\n",
      "Loss [1, 110](epoch, minibatch):  3.891928863525391\n",
      "Loss [1, 120](epoch, minibatch):  3.8644190979003907\n",
      "Loss [1, 130](epoch, minibatch):  3.8380124282836916\n",
      "Loss [1, 140](epoch, minibatch):  3.8108840560913086\n",
      "Loss [1, 150](epoch, minibatch):  3.77370174407959\n",
      "Loss [1, 160](epoch, minibatch):  3.749676475524902\n",
      "Loss [1, 170](epoch, minibatch):  3.7158573913574218\n",
      "Loss [1, 180](epoch, minibatch):  3.690536117553711\n",
      "Loss [1, 190](epoch, minibatch):  3.653006134033203\n",
      "Loss [1, 200](epoch, minibatch):  3.6245897674560545\n",
      "Loss [1, 210](epoch, minibatch):  3.591790199279785\n",
      "Loss [1, 220](epoch, minibatch):  3.5593911361694337\n",
      "Loss [1, 230](epoch, minibatch):  3.5283361434936524\n",
      "Loss [1, 240](epoch, minibatch):  3.49509822845459\n",
      "Loss [1, 250](epoch, minibatch):  3.460625686645508\n",
      "Loss [1, 260](epoch, minibatch):  3.4259143829345704\n",
      "Loss [1, 270](epoch, minibatch):  3.389627571105957\n",
      "Loss [1, 280](epoch, minibatch):  3.3730615615844726\n",
      "Loss [1, 290](epoch, minibatch):  3.3467290115356447\n",
      "Loss [1, 300](epoch, minibatch):  3.3108380889892577\n",
      "Loss [1, 310](epoch, minibatch):  3.262268295288086\n",
      "Loss [1, 320](epoch, minibatch):  3.2437338256835937\n",
      "Loss [1, 330](epoch, minibatch):  3.2165892791748045\n",
      "Loss [1, 340](epoch, minibatch):  3.1818219375610353\n",
      "Loss [1, 350](epoch, minibatch):  3.1418786239624024\n",
      "Loss [1, 360](epoch, minibatch):  3.115684700012207\n",
      "Loss [1, 370](epoch, minibatch):  3.0760671997070315\n",
      "Loss [1, 380](epoch, minibatch):  3.053421974182129\n",
      "Loss [1, 390](epoch, minibatch):  3.019377040863037\n",
      "Loss [1, 400](epoch, minibatch):  2.9688548851013183\n",
      "Loss [1, 410](epoch, minibatch):  2.930157470703125\n",
      "Loss [1, 420](epoch, minibatch):  2.8924404335021974\n",
      "Loss [1, 430](epoch, minibatch):  2.8538686752319338\n",
      "Loss [1, 440](epoch, minibatch):  2.8204399490356447\n",
      "Loss [1, 450](epoch, minibatch):  2.7939930534362794\n",
      "Loss [1, 460](epoch, minibatch):  2.7621104240417482\n",
      "Loss [1, 470](epoch, minibatch):  2.7200218772888185\n",
      "Loss [1, 480](epoch, minibatch):  2.682268810272217\n",
      "Loss [1, 490](epoch, minibatch):  2.6324445724487306\n",
      "Loss [1, 500](epoch, minibatch):  2.595284938812256\n",
      "Loss [1, 510](epoch, minibatch):  2.555004024505615\n",
      "Loss [1, 520](epoch, minibatch):  2.528271656036377\n",
      "Loss [1, 530](epoch, minibatch):  2.494454345703125\n",
      "Loss [1, 540](epoch, minibatch):  2.442496032714844\n",
      "Loss [1, 550](epoch, minibatch):  2.3794939804077146\n",
      "Loss [1, 560](epoch, minibatch):  2.370011329650879\n",
      "Loss [1, 570](epoch, minibatch):  2.328593330383301\n",
      "Loss [1, 580](epoch, minibatch):  2.2939527320861814\n",
      "Loss [1, 590](epoch, minibatch):  2.245449676513672\n",
      "Loss [1, 600](epoch, minibatch):  2.204813175201416\n",
      "Loss [1, 610](epoch, minibatch):  2.1752909278869628\n",
      "Loss [1, 620](epoch, minibatch):  2.130866470336914\n",
      "Loss [1, 630](epoch, minibatch):  2.1119061088562012\n",
      "Loss [1, 640](epoch, minibatch):  2.058936653137207\n",
      "Loss [1, 650](epoch, minibatch):  2.0483992004394533\n",
      "Loss [1, 660](epoch, minibatch):  2.0105850219726564\n",
      "Loss [1, 670](epoch, minibatch):  1.9784428596496582\n",
      "Loss [1, 680](epoch, minibatch):  1.9157929229736328\n",
      "Loss [1, 690](epoch, minibatch):  1.8949536895751953\n",
      "Loss [1, 700](epoch, minibatch):  1.8915213394165038\n",
      "Loss [1, 710](epoch, minibatch):  1.8574664306640625\n",
      "Loss [1, 720](epoch, minibatch):  1.8162336921691895\n",
      "Loss [1, 730](epoch, minibatch):  1.776696720123291\n",
      "Loss [1, 740](epoch, minibatch):  1.7903103256225585\n",
      "Loss [1, 750](epoch, minibatch):  1.7668997764587402\n",
      "Loss [1, 760](epoch, minibatch):  1.7465812492370605\n",
      "Loss [1, 770](epoch, minibatch):  1.7076605224609376\n",
      "Loss [1, 780](epoch, minibatch):  1.6654108619689942\n",
      "Loss [1, 790](epoch, minibatch):  1.6287789535522461\n",
      "Loss [1, 800](epoch, minibatch):  1.6462138843536378\n",
      "Loss [1, 810](epoch, minibatch):  1.6522724533081055\n",
      "Loss [1, 820](epoch, minibatch):  1.6260073280334473\n",
      "Loss [1, 830](epoch, minibatch):  1.5672192001342773\n",
      "Loss [1, 840](epoch, minibatch):  1.5726080226898194\n",
      "Loss [1, 850](epoch, minibatch):  1.5698147487640381\n",
      "Loss [1, 860](epoch, minibatch):  1.5289766311645507\n",
      "Loss [1, 870](epoch, minibatch):  1.5070903968811036\n",
      "Loss [1, 880](epoch, minibatch):  1.4907110595703126\n",
      "Loss [1, 890](epoch, minibatch):  1.4604751873016357\n",
      "Loss [1, 900](epoch, minibatch):  1.4441655635833741\n",
      "Loss [1, 910](epoch, minibatch):  1.4441843700408936\n",
      "Loss [1, 920](epoch, minibatch):  1.4054897594451905\n",
      "Loss [1, 930](epoch, minibatch):  1.3985671520233154\n",
      "Loss [1, 940](epoch, minibatch):  1.3726292514801026\n",
      "Loss [1, 950](epoch, minibatch):  1.3535796070098878\n",
      "Loss [1, 960](epoch, minibatch):  1.3426537609100342\n",
      "Loss [1, 970](epoch, minibatch):  1.3505132007598877\n",
      "Loss [1, 980](epoch, minibatch):  1.3428179454803466\n",
      "Loss [1, 990](epoch, minibatch):  1.2967589950561524\n",
      "Loss [1, 1000](epoch, minibatch):  1.2826566410064697\n",
      "Loss [1, 1010](epoch, minibatch):  1.2845718383789062\n",
      "Loss [1, 1020](epoch, minibatch):  1.2818275165557862\n",
      "Loss [1, 1030](epoch, minibatch):  1.2614459419250488\n",
      "Loss [1, 1040](epoch, minibatch):  1.254185676574707\n",
      "Loss [1, 1050](epoch, minibatch):  1.2530350589752197\n",
      "Loss [1, 1060](epoch, minibatch):  1.2643112659454345\n",
      "Loss [1, 1070](epoch, minibatch):  1.2335375022888184\n",
      "Loss [1, 1080](epoch, minibatch):  1.2544158458709718\n",
      "Loss [1, 1090](epoch, minibatch):  1.232620496749878\n",
      "Loss [1, 1100](epoch, minibatch):  1.197688980102539\n",
      "Loss [1, 1110](epoch, minibatch):  1.1345842742919923\n",
      "Loss [1, 1120](epoch, minibatch):  1.17099986076355\n",
      "Loss [1, 1130](epoch, minibatch):  1.1570148944854737\n",
      "Loss [1, 1140](epoch, minibatch):  1.146307716369629\n",
      "Loss [1, 1150](epoch, minibatch):  1.1750636291503906\n",
      "Loss [1, 1160](epoch, minibatch):  1.1268333435058593\n",
      "Loss [1, 1170](epoch, minibatch):  1.145120611190796\n",
      "Loss [1, 1180](epoch, minibatch):  1.1211460304260255\n",
      "Loss [1, 1190](epoch, minibatch):  1.1024587535858155\n",
      "Loss [1, 1200](epoch, minibatch):  1.099001922607422\n",
      "Loss [1, 1210](epoch, minibatch):  1.0931144905090333\n",
      "Loss [1, 1220](epoch, minibatch):  1.0633116626739503\n",
      "Loss [1, 1230](epoch, minibatch):  1.0660169410705567\n",
      "Loss [1, 1240](epoch, minibatch):  1.0740360164642333\n",
      "Loss [1, 1250](epoch, minibatch):  1.057340955734253\n",
      "Loss [1, 1260](epoch, minibatch):  1.0096132373809814\n",
      "Loss [1, 1270](epoch, minibatch):  1.0439513969421386\n",
      "Loss [1, 1280](epoch, minibatch):  1.010416259765625\n",
      "Loss [1, 1290](epoch, minibatch):  1.0332942867279054\n",
      "Loss [1, 1300](epoch, minibatch):  1.001277332305908\n",
      "Loss [1, 1310](epoch, minibatch):  1.0155709743499757\n",
      "Loss [1, 1320](epoch, minibatch):  0.9967040824890137\n",
      "Loss [1, 1330](epoch, minibatch):  0.9895166778564453\n",
      "Loss [1, 1340](epoch, minibatch):  0.9644554901123047\n",
      "Loss [1, 1350](epoch, minibatch):  0.9942715167999268\n",
      "Loss [1, 1360](epoch, minibatch):  0.9456527137756348\n",
      "Loss [1, 1370](epoch, minibatch):  0.9415880012512207\n",
      "Loss [1, 1380](epoch, minibatch):  0.9676083755493164\n",
      "Loss [1, 1390](epoch, minibatch):  0.9208704853057861\n",
      "Loss [1, 1400](epoch, minibatch):  0.9440590953826904\n",
      "Loss [1, 1410](epoch, minibatch):  0.940912504196167\n",
      "Loss [1, 1420](epoch, minibatch):  0.923487491607666\n",
      "Loss [1, 1430](epoch, minibatch):  0.8915440273284913\n",
      "Loss [1, 1440](epoch, minibatch):  0.9006795501708984\n",
      "Loss [1, 1450](epoch, minibatch):  0.902736873626709\n",
      "Loss [1, 1460](epoch, minibatch):  0.89049147605896\n",
      "Loss [1, 1470](epoch, minibatch):  0.875037612915039\n",
      "Loss [1, 1480](epoch, minibatch):  0.8768610477447509\n",
      "Loss [1, 1490](epoch, minibatch):  0.890999698638916\n",
      "Loss [1, 1500](epoch, minibatch):  0.8442884540557861\n",
      "Loss [1, 1510](epoch, minibatch):  0.8372852754592895\n",
      "Loss [1, 1520](epoch, minibatch):  0.8474396419525146\n",
      "Loss [1, 1530](epoch, minibatch):  0.8477045583724976\n",
      "Loss [1, 1540](epoch, minibatch):  0.8417156028747559\n",
      "Loss [1, 1550](epoch, minibatch):  0.8129858779907226\n",
      "Loss [1, 1560](epoch, minibatch):  0.8168552589416503\n",
      "Loss [1, 1570](epoch, minibatch):  0.803260645866394\n",
      "Loss [1, 1580](epoch, minibatch):  0.8142300462722778\n",
      "Loss [1, 1590](epoch, minibatch):  0.8103632259368897\n",
      "Loss [1, 1600](epoch, minibatch):  0.8036457347869873\n",
      "Loss [1, 1610](epoch, minibatch):  0.7798798274993897\n",
      "Loss [1, 1620](epoch, minibatch):  0.830717248916626\n",
      "Loss [1, 1630](epoch, minibatch):  0.8005039024353028\n",
      "Loss [1, 1640](epoch, minibatch):  0.7994377088546752\n",
      "Loss [1, 1650](epoch, minibatch):  0.7998867082595825\n",
      "Loss [1, 1660](epoch, minibatch):  0.808482084274292\n",
      "Loss [1, 1670](epoch, minibatch):  0.7683767747879028\n",
      "Loss [1, 1680](epoch, minibatch):  0.7710726118087768\n",
      "Loss [1, 1690](epoch, minibatch):  0.7710536098480225\n",
      "Loss [1, 1700](epoch, minibatch):  0.7590617990493774\n",
      "Loss [1, 1710](epoch, minibatch):  0.7489294338226319\n",
      "Loss [1, 1720](epoch, minibatch):  0.7567568588256836\n",
      "Loss [1, 1730](epoch, minibatch):  0.7549548101425171\n",
      "Loss [1, 1740](epoch, minibatch):  0.7530079793930053\n",
      "Loss [1, 1750](epoch, minibatch):  0.7239363765716553\n",
      "Loss [1, 1760](epoch, minibatch):  0.7381086111068725\n",
      "Loss [1, 1770](epoch, minibatch):  0.707736177444458\n",
      "Loss [1, 1780](epoch, minibatch):  0.7115133047103882\n",
      "Loss [1, 1790](epoch, minibatch):  0.7306544065475464\n",
      "Loss [1, 1800](epoch, minibatch):  0.7263590240478516\n",
      "Loss [1, 1810](epoch, minibatch):  0.7115851640701294\n",
      "Loss [1, 1820](epoch, minibatch):  0.7212007474899292\n",
      "Loss [1, 1830](epoch, minibatch):  0.7228969717025757\n",
      "Loss [1, 1840](epoch, minibatch):  0.7263686561584473\n",
      "Loss [1, 1850](epoch, minibatch):  0.6993224668502808\n",
      "Loss [1, 1860](epoch, minibatch):  0.6962772703170776\n",
      "Loss [1, 1870](epoch, minibatch):  0.7024753952026367\n",
      "Loss [1, 1880](epoch, minibatch):  0.7076179933547974\n",
      "Loss [1, 1890](epoch, minibatch):  0.7069331216812134\n",
      "Loss [1, 1900](epoch, minibatch):  0.6984501552581787\n",
      "Loss [1, 1910](epoch, minibatch):  0.695437240600586\n",
      "Loss [1, 1920](epoch, minibatch):  0.6755648183822632\n",
      "Loss [1, 1930](epoch, minibatch):  0.6794145965576172\n",
      "Loss [1, 1940](epoch, minibatch):  0.7109082984924316\n",
      "Loss [1, 1950](epoch, minibatch):  0.6558783817291259\n",
      "Loss [1, 1960](epoch, minibatch):  0.6727438259124756\n",
      "Loss [1, 1970](epoch, minibatch):  0.6829514932632447\n",
      "Loss [1, 1980](epoch, minibatch):  0.6605401754379272\n",
      "Loss [1, 1990](epoch, minibatch):  0.667973313331604\n",
      "Loss [1, 2000](epoch, minibatch):  0.6489651679992676\n",
      "Loss [1, 2010](epoch, minibatch):  0.6518737888336181\n",
      "Loss [1, 2020](epoch, minibatch):  0.6129028940200806\n",
      "Loss [1, 2030](epoch, minibatch):  0.6655030775070191\n",
      "Loss [1, 2040](epoch, minibatch):  0.642412223815918\n",
      "Loss [1, 2050](epoch, minibatch):  0.6448768758773804\n",
      "Loss [1, 2060](epoch, minibatch):  0.6457065153121948\n",
      "Loss [1, 2070](epoch, minibatch):  0.6592953062057495\n",
      "Loss [1, 2080](epoch, minibatch):  0.6265512418746948\n",
      "Loss [1, 2090](epoch, minibatch):  0.6573200130462646\n",
      "Loss [1, 2100](epoch, minibatch):  0.6522221040725708\n",
      "Loss [1, 2110](epoch, minibatch):  0.6341485977172852\n",
      "Loss [1, 2120](epoch, minibatch):  0.6512006568908691\n",
      "Loss [1, 2130](epoch, minibatch):  0.6151439237594605\n",
      "Loss [1, 2140](epoch, minibatch):  0.6634297847747803\n",
      "Loss [1, 2150](epoch, minibatch):  0.6402875709533692\n",
      "Loss [1, 2160](epoch, minibatch):  0.63460196018219\n",
      "Loss [1, 2170](epoch, minibatch):  0.6072035694122314\n",
      "Loss [1, 2180](epoch, minibatch):  0.6321698713302613\n",
      "Loss [1, 2190](epoch, minibatch):  0.6201126623153687\n",
      "Loss [1, 2200](epoch, minibatch):  0.6124522066116334\n",
      "Loss [1, 2210](epoch, minibatch):  0.6096563911437989\n",
      "Loss [1, 2220](epoch, minibatch):  0.6042641019821167\n",
      "Loss [1, 2230](epoch, minibatch):  0.6085904359817504\n",
      "Loss [1, 2240](epoch, minibatch):  0.5926245927810669\n",
      "Loss [1, 2250](epoch, minibatch):  0.6193662166595459\n",
      "Loss [1, 2260](epoch, minibatch):  0.5752478790283203\n",
      "Loss [1, 2270](epoch, minibatch):  0.5989400768280029\n",
      "Loss [1, 2280](epoch, minibatch):  0.606913571357727\n",
      "Loss [1, 2290](epoch, minibatch):  0.6091134738922119\n",
      "Loss [1, 2300](epoch, minibatch):  0.6126832580566406\n",
      "Loss [1, 2310](epoch, minibatch):  0.5748363971710205\n",
      "Loss [1, 2320](epoch, minibatch):  0.5707284879684448\n",
      "Loss [1, 2330](epoch, minibatch):  0.5887586593627929\n",
      "Loss [1, 2340](epoch, minibatch):  0.5854993152618408\n",
      "Loss [1, 2350](epoch, minibatch):  0.5851978731155395\n",
      "Loss [1, 2360](epoch, minibatch):  0.5650901460647583\n",
      "Loss [1, 2370](epoch, minibatch):  0.5603242874145508\n",
      "Loss [1, 2380](epoch, minibatch):  0.5822420644760132\n",
      "Loss [1, 2390](epoch, minibatch):  0.5840685415267944\n",
      "Loss [1, 2400](epoch, minibatch):  0.5960470962524415\n",
      "Loss [1, 2410](epoch, minibatch):  0.5869652652740478\n",
      "Loss [1, 2420](epoch, minibatch):  0.5798225212097168\n",
      "Loss [1, 2430](epoch, minibatch):  0.5727214813232422\n",
      "Loss [1, 2440](epoch, minibatch):  0.57567307472229\n",
      "Loss [1, 2450](epoch, minibatch):  0.5795663833618164\n",
      "Loss [1, 2460](epoch, minibatch):  0.5606582784652709\n",
      "Loss [1, 2470](epoch, minibatch):  0.5625359535217285\n",
      "Loss [1, 2480](epoch, minibatch):  0.545802173614502\n",
      "Loss [1, 2490](epoch, minibatch):  0.5599944877624512\n",
      "Loss [1, 2500](epoch, minibatch):  0.5697767257690429\n",
      "Loss [1, 2510](epoch, minibatch):  0.5583019971847534\n",
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    losses = []\n",
    "    running_loss = 0\n",
    "    print(f'dtloader len:{len(train_dataloader)}')\n",
    "    for i, inp in tqdm(enumerate(train_dataloader)):\n",
    "        x, y = inp\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optim.zero_grad()\n",
    "\n",
    "        pred = net(x.unsqueeze(1).expand(-1, 3, -1, -1).type(torch.cuda.FloatTensor)).to(device)\n",
    "        loss = crit(pred.to(device), y.to(device))\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i%10 == 0 and i > 0:\n",
    "            print(f'Loss [{epoch+1}, {i}](epoch, minibatch): ', running_loss / 100)\n",
    "            running_loss = 0.0\n",
    "\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "            \n",
    "print('Training Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e951a5a4-a24f-4ad9-8a18-9a1e652b0030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "2024-05-13 17:26:24.796912: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/krapchatovmi/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
       "2024-05-13 17:26:24.796963: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
       "2024-05-13 17:26:26.665716: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/krapchatovmi/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
       "2024-05-13 17:26:26.665897: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/krapchatovmi/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
       "2024-05-13 17:26:26.666033: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/krapchatovmi/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
       "2024-05-13 17:26:26.666166: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/krapchatovmi/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
       "2024-05-13 17:26:27.251693: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/krapchatovmi/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
       "2024-05-13 17:26:27.251973: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/krapchatovmi/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
       "2024-05-13 17:26:27.252001: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
       "Skipping registering GPU devices...\n",
       "\n",
       "NOTE: Using experimental fast data loading logic. To disable, pass\n",
       "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
       "    https://github.com/tensorflow/tensorboard/issues/4784\n",
       "\n",
       "Address already in use\n",
       "Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir tb_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761898b0-31cc-4f8a-aa55-085c2ccef679",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70e2d6b4-4e08-4263-87f1-c9976885e7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = './pred.txt'\n",
    "\n",
    "test_reader = LMDBReader(test_path)\n",
    "test_reader.open()\n",
    "test_helper = HWDBDatasetHelper(test_reader, prefix='Test')\n",
    "\n",
    "test_dataset = HWDBDataset(test_helper)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "601251dd-3c51-4384-93e7-7ee99d01ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "crit.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f513f46-9219-47bd-94ad-ed95402c20f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e139cab7790f45afbbfef2fb139ce21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = []\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for X, _ in tqdm(test_loader):\n",
    "        xx = X.unsqueeze(1).expand(-1, 3, -1, -1)\n",
    "        outputs = net(xx.to(device).type(torch.cuda.FloatTensor))\n",
    "        \n",
    "        logits = crit.get_logits(outputs)\n",
    "        classes = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        preds.extend(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b2c0f9fc-8e28-4d39-beb8-1f16e660dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pred_path, 'w') as f_pred:\n",
    "    for idx, pred in enumerate(preds):\n",
    "        name = test_helper.namelist[idx]\n",
    "        cls = train_helper.vocabulary.class_by_index(pred)\n",
    "        print(name, cls, file=f_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c131e909-c4b4-444e-a6da-70c21f534fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9102190147619581"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from course_intro_ocr_t2.evaluate import evaluate\n",
    "\n",
    "evaluate(gt_path, pred_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
